{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "from transformers import BertModel, BertForQuestionAnswering, AutoTokenizer\n",
    "from dataset import SquadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define save and load path\n",
    "bert_dir = \"model_weights/BERT/\"\n",
    "\n",
    "load_path = bert_dir + \"04-04-2023-15-41\" # add date_time as name\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 8\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForQuestionAnswering.from_pretrained(load_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fn_1 = Accuracy(\"multiclass\", num_classes=384, top_k=1)\n",
    "f1_fn_1 = F1Score(\"multiclass\", num_classes=384, top_k=1)\n",
    "\n",
    "acc_fn_3 = Accuracy(\"multiclass\", num_classes=384, top_k=3)\n",
    "f1_fn_3 = F1Score(\"multiclass\", num_classes=384, top_k=3)\n",
    "\n",
    "acc_fn_5 = Accuracy(\"multiclass\", num_classes=384, top_k=5)\n",
    "f1_fn_5 = F1Score(\"multiclass\", num_classes=384, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (C:/Users/Dell/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "265dcacd12cb422dbda132cee12389a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432d8639e2ed4ee2aa499cde3a8bdf06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset and dataloaders\n",
    "squad_dataset = SquadDataset(tokenizer, max_length=384, batch_size=batch_size, eval=True)\n",
    "eval_dataloader = squad_dataset.eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.000000004.1697\n",
      "Top-1 Accuracy: 0.05000000\n",
      "Top-3 Accuracy: 0.11250000\n",
      "Top-5 Accuracy: 0.12500000\n",
      "Top-1 F1-Score: 0.05000000\n",
      "Top-3 F1-Score: 0.05625000\n",
      "Top-5 F1-Score: 0.04166667\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "eval_loss, top1_acc, top3_acc, top5_acc, top1_f1, top3_f1, top5_f1 = 0, 0, 0, 0, 0, 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(eval_dataloader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_positions = batch[\"start_positions\"].to(device)\n",
    "        end_positions = batch[\"end_positions\"].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        start_acc_1, start_acc_3, start_acc_5 = acc_fn_1(start_logits, start_positions), acc_fn_3(start_logits, start_positions), acc_fn_5(start_logits, start_positions) \n",
    "        end_acc_1, end_acc_3, end_acc_5 = acc_fn_1(end_logits, end_positions), acc_fn_3(end_logits, end_positions), acc_fn_5(end_logits, end_positions)\n",
    "        \n",
    "        start_f1_1, start_f1_3, start_f1_5 = f1_fn_1(start_logits, start_positions), f1_fn_3(start_logits, start_positions), f1_fn_5(start_logits, start_positions) \n",
    "        end_f1_1, end_f1_3, end_f1_5 = f1_fn_1(end_logits, end_positions), f1_fn_3(end_logits, end_positions), f1_fn_5(end_logits, end_positions)\n",
    "        \n",
    "        top1_acc += ((start_acc_1 * input_ids.size(0)) + (end_acc_1 * input_ids.size(0)))/2\n",
    "        top3_acc += ((start_acc_3 * input_ids.size(0)) + (end_acc_3 * input_ids.size(0)))/2\n",
    "        top5_acc += ((start_acc_5 * input_ids.size(0)) + (end_acc_5 * input_ids.size(0)))/2\n",
    "        \n",
    "        top1_f1 += ((start_f1_1 * input_ids.size(0)) + (end_f1_1 * input_ids.size(0)))/2\n",
    "        top3_f1 += ((start_f1_3 * input_ids.size(0)) + (end_f1_3 * input_ids.size(0)))/2\n",
    "        top5_f1 += ((start_f1_5 * input_ids.size(0)) + (end_f1_5 * input_ids.size(0)))/2\n",
    "        \n",
    "        if (batch_idx) % 100 == 0:\n",
    "            print(f\"Batch: {batch_idx}/{len(eval_dataloader)}, Loss: {loss.item():.4f}\", end=\"\\r\")\n",
    "\n",
    "eval_loss /= len(squad_dataset.eval_dataset)\n",
    "top1_acc /= len(squad_dataset.eval_dataset)\n",
    "top3_acc /= len(squad_dataset.eval_dataset)\n",
    "top5_acc /= len(squad_dataset.eval_dataset)\n",
    "top1_f1 /= len(squad_dataset.eval_dataset)\n",
    "top3_f1 /= len(squad_dataset.eval_dataset)\n",
    "top5_f1 /= len(squad_dataset.eval_dataset)\n",
    "\n",
    "print(f\"Eval Loss: {eval_loss:.8f}\\nTop-1 Accuracy: {top1_acc:.8f}\\nTop-3 Accuracy: {top3_acc:.8f}\\nTop-5 Accuracy: {top5_acc:.8f}\\nTop-1 F1-Score: {top1_f1:.8f}\\nTop-3 F1-Score: {top3_f1:.8f}\\nTop-5 F1-Score: {top5_f1:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "model.eval()\n",
    "eval_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(eval_dataloader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_positions = batch[\"start_positions\"].to(device)\n",
    "        end_positions = batch[\"end_positions\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        eval_loss += loss.item() * input_ids.size(0)\n",
    "        if (batch_idx) % 100 == 0:\n",
    "            print(f\"Batch: {batch_idx}/{len(eval_dataloader)}, Loss: {loss.item():.4f}\", end=\"\\r\")\n",
    "\n",
    "\n",
    "eval_loss /= len(squad_dataset.eval_dataset)\n",
    "\n",
    "print(f\"Eval Loss: {eval_loss:.8f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

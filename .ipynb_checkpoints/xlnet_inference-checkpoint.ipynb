{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "from transformers import XLNetForQuestionAnsweringSimple, AutoTokenizer\n",
    "from dataset import SquadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define save and load path\n",
    "xlnet_dir = \"model_weights/XLNet/\"\n",
    "\n",
    "load_path = xlnet_dir + \"06-04-2023-17-30\" # add date_time as name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 8\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\", padding_side=\"right\")\n",
    "model = XLNetForQuestionAnsweringSimple.from_pretrained(load_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (C:/Users/Dell/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6491c4b6927425e95059411b00c1b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d295b0e4c1a44bf5830a93659a48d5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset and dataloaders\n",
    "squad_dataset = SquadDataset(tokenizer, max_length=384, batch_size=batch_size, eval=True)\n",
    "eval_dataloader = squad_dataset.eval_dataloader\n",
    "\n",
    "eval_dataset = squad_dataset.eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(idx, eval_dataloader, eval_dataset, model, tokenizer):\n",
    "    \n",
    "    raw_sample = eval_dataset[idx]\n",
    "    input_sample = eval_dataloader.dataset[idx]\n",
    "    \n",
    "    input_ids = input_sample[\"input_ids\"].unsqueeze(0).to(device)\n",
    "    attention_mask = input_sample[\"attention_mask\"].unsqueeze(0).to(device)\n",
    "    start_positions = input_sample[\"start_positions\"].unsqueeze(0).to(device)\n",
    "    end_positions = input_sample[\"end_positions\"].unsqueeze(0).to(device)\n",
    "    \n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "    \n",
    "    start_span = outputs.start_logits.cpu().argmax()\n",
    "    end_span = outputs.end_logits.cpu().argmax()\n",
    "    \n",
    "    answer_tokens = input_ids[0, start_span:end_span+1]\n",
    "    predicted_answer = tokenizer.decode(answer_tokens)\n",
    "    \n",
    "    question = raw_sample[\"question\"]\n",
    "    context = raw_sample[\"context\"]\n",
    "    gt_answer = raw_sample[\"answers\"]\n",
    "    \n",
    "    print(\"Context:\\n\" + context + \"\\n\\nQuestion:\\n\" + question + \"\\n\\nGround Truth answer:\\n\", gt_answer, \n",
    "          \"\\n\\nPredicted answer:\\n\" + predicted_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Internet2 is a not-for-profit United States computer networking consortium led by members from the research and education communities, industry, and government. The Internet2 community, in partnership with Qwest, built the first Internet2 Network, called Abilene, in 1998 and was a prime investor in the National LambdaRail (NLR) project. In 2006, Internet2 announced a partnership with Level 3 Communications to launch a brand new nationwide network, boosting its capacity from 10 Gbit/s to 100 Gbit/s. In October, 2007, Internet2 officially retired Abilene and now refers to its new, higher capacity network as the Internet2 Network.\n",
      "\n",
      "Question:\n",
      "Who did internet2 partner with \n",
      "\n",
      "Ground Truth answer:\n",
      " {'text': ['a partnership with Level 3 Communications to launch a brand new nationwide network', 'Level 3 Communications', 'Qwest'], 'answer_start': [368, 387, 206]} \n",
      "\n",
      "Predicted answer:\n",
      "Qwest\n"
     ]
    }
   ],
   "source": [
    "inference(4903, eval_dataloader, eval_dataset, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "With Istanbul as its capital and control of lands around the Mediterranean basin, the Ottoman Empire was at the center of interactions between the Eastern and Western worlds for six centuries. Following a long period of military setbacks against European powers, the Ottoman Empire gradually declined into the late nineteenth century. The empire allied with Germany in the early 20th century, with the imperial ambition of recovering its lost territories, but it dissolved in the aftermath of World War I, leading to the emergence of the new state of Turkey in the Ottoman Anatolian heartland, as well as the creation of modern Balkan and Middle Eastern states, thus ending Turkish colonial ambitions.\n",
      "\n",
      "Question:\n",
      "Which country today is a remnant of the Ottoman empire?\n",
      "\n",
      "Ground Truth answer:\n",
      " {'text': ['Turkey', 'Turkey', 'Turkey', 'Turkey', 'Turkey'], 'answer_start': [551, 551, 551, 551, 551]} \n",
      "\n",
      "Predicted answer:\n",
      "Germany\n"
     ]
    }
   ],
   "source": [
    "inference(10000, eval_dataloader, eval_dataset, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "The league eventually narrowed the bids to three sites: New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium, and the San Francisco Bay Area's Levi's Stadium.\n",
      "\n",
      "Question:\n",
      "What three stadiums did the NFL decide between for the game?\n",
      "\n",
      "Ground Truth answer:\n",
      " {'text': [\"New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium, and the San Francisco Bay Area's Levi's Stadium\", \"New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium, and the San Francisco Bay Area's Levi's Stadium.\", \"New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium, and the San Francisco Bay Area's Levi's Stadium.\"], 'answer_start': [56, 56, 56]} \n",
      "\n",
      "Predicted answer:\n",
      "New Orleans' Mercedes-Benz Superdome\n"
     ]
    }
   ],
   "source": [
    "inference(125, eval_dataloader, eval_dataset, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Exceptional examples of the bourgeois architecture of the later periods were not restored by the communist authorities after the war (like mentioned Kronenberg Palace and Insurance Company Rosja building) or they were rebuilt in socialist realism style (like Warsaw Philharmony edifice originally inspired by Palais Garnier in Paris). Despite that the Warsaw University of Technology building (1899–1902) is the most interesting of the late 19th-century architecture. Some 19th-century buildings in the Praga district (the Vistula’s right bank) have been restored although many have been poorly maintained. Warsaw’s municipal government authorities have decided to rebuild the Saxon Palace and the Brühl Palace, the most distinctive buildings in prewar Warsaw.\n",
      "\n",
      "Question:\n",
      "What style was the Warsaw Philharmony edifice built in?\n",
      "\n",
      "Ground Truth answer:\n",
      " {'text': ['socialist realism', 'socialist realism', 'socialist realism'], 'answer_start': [229, 229, 229]} \n",
      "\n",
      "Predicted answer:\n",
      "socialist realism\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "idx = random.randint(0,len(eval_dataset))\n",
    "\n",
    "inference(idx, eval_dataloader, eval_dataset, model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
